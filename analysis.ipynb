{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5c930e",
   "metadata": {},
   "source": [
    "# Project Management Dataset Analysis\n",
    "\n",
    "This notebook explores a synthetic project management dataset and builds a predictive model to determine project success.\n",
    "\n",
    "The data is generated for demonstration purposes and includes variables such as team size, budget, duration, complexity score, methodology used, manager's experience, number of changes during the project, risk score, domain, and the project outcome (`status`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('synthetic_project_data.csv')\n",
    "\n",
    "# Display first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c673a32a",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "Let's look at summary statistics for numeric variables and the distribution of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf5e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numeric features\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of categorical variables\n",
    "for col in ['methodology', 'domain', 'status']:\n",
    "    print(f\"\n",
    "{col} distribution:\")\n",
    "    print(data[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdddbfe",
   "metadata": {},
   "source": [
    "## Exploratory Visualizations\n",
    "\n",
    "Visualize distributions and relationships between features and the project outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe6a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for numeric features\n",
    "numeric_cols = ['team_size', 'budget_k', 'duration_months', 'complexity_score', 'manager_experience_yrs', 'num_changes', 'risk_score']\n",
    "fig, axs = plt.subplots(len(numeric_cols), 1, figsize=(8, 3*len(numeric_cols)))\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    sns.histplot(data[col], kde=True, ax=axs[i], color='skyblue')\n",
    "    axs[i].set_title(f'Distribution of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee97231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for numeric features\n",
    "plt.figure(figsize=(8,6))\n",
    "corr = data[numeric_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Numeric Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between complexity_score and risk_score, colored by outcome\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x='complexity_score', y='risk_score', hue='status', data=data)\n",
    "plt.title('Complexity vs Risk by Project Outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ebbc1",
   "metadata": {},
   "source": [
    "## Predictive Modeling\n",
    "\n",
    "We'll build a classification model to predict whether a project will be successful. We'll use a Random Forest classifier and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10028be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data.drop('status', axis=1)\n",
    "y = data['status']\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "cat_cols = ['methodology', 'domain']\n",
    "num_cols = [col for col in X.columns if col not in cat_cols + ['project_id']]\n",
    "\n",
    "# Preprocess: One-hot encode categorical variables and pass numeric variables unchanged\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first'), cat_cols)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Build the model pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('\n",
    "Classification Report:\n",
    "', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:\n",
    "', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "# To access feature importances, we need to get feature names after one-hot encoding\n",
    "# Extract the trained RandomForestClassifier\n",
    "rf = model.named_steps['classifier']\n",
    "# Get one-hot encoder categories\n",
    "ohe = model.named_steps['preprocessor'].named_transformers_['cat']\n",
    "ohe_feature_names = ohe.get_feature_names_out(cat_cols)\n",
    "# Combine with numeric column names\n",
    "feature_names = list(ohe_feature_names) + num_cols + ['project_id']  # original features order\n",
    "# Get importances\n",
    "importances = rf.feature_importances_\n",
    "# Combine into a DataFrame and sort\n",
    "importances_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "importances_df = importances_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='importance', y='feature', data=importances_df.head(10), palette='viridis')\n",
    "plt.title('Top 10 Feature Importances from Random Forest')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6095845",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this analysis, we explored a synthetic project management dataset and built a classification model to predict project success.\n",
    "\n",
    "Key takeaways:\n",
    "\n",
    "- Team size and manager experience were positively correlated with project success.\n",
    "- Higher complexity, risk, budget, and number of changes tended to decrease the probability of success.\n",
    "- The Random Forest model achieved good accuracy on the synthetic dataset, with feature importances highlighting the most influential factors.\n",
    "\n",
    "Feel free to experiment with the code and adjust model parameters to see how the results change. Since the dataset is synthetic, the analysis is meant to showcase analytical techniques rather than produce actionable real-world insights."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
